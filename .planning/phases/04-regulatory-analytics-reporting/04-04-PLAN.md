---
phase: 04-regulatory-analytics-reporting
plan: 04
type: execute
wave: 2
depends_on: ["04-01", "04-02", "04-03"]
files_modified:
  - services/regulatory_svc/app/routes/reports.py
  - services/common/export.py
autonomous: true

must_haves:
  truths:
    - "CSV export produces RFC 4180 compliant output with proper quoting"
    - "Excel export uses openpyxl with cell formatting and number formats"
    - "Regulatory reports include summary and audit trail sheets"
  artifacts:
    - path: "services/regulatory_svc/app/routes/reports.py"
      provides: "Export endpoints for CSV and Excel"
      exports: ["GET /reports/regulatory/{portfolio_id}/export"]
      min_lines: 120
    - path: "services/common/export.py"
      provides: "Shared export utilities"
      exports: ["export_to_csv", "export_to_excel"]
      min_lines: 150
  key_links:
    - from: "export_to_excel"
      to: "openpyxl.Workbook"
      via: "workbook creation with formatting"
      pattern: "from openpyxl import Workbook"
    - from: "GET /reports/.*export"
      to: "regulatory_metrics table"
      via: "SQL query for report data"
      pattern: "SELECT.*regulatory_metrics"
---

<objective>
Implement CSV/Excel export pipeline for regulatory reports. Enable Phase 4 frontend to download regulatory data (CECL allowance, Basel RWA, audit trail) in standard formats for downstream systems and audit.

Purpose: Deliver RPT-03 (export to CSV/Excel). Provide audit-compliant export with formatting for financial reporting.

Output: Export endpoints with openpyxl-based Excel generation and Python csv module CSV generation.
</objective>

<execution_context>
@C:/Users/omack/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/omack/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-regulatory-analytics-reporting/04-RESEARCH.md
@.planning/phases/04-regulatory-analytics-reporting/04-03-PLAN.md

# Existing routes
@services/regulatory_svc/app/routes/cecl.py
@services/regulatory_svc/app/routes/basel.py
@services/regulatory_svc/app/routes/audit.py

# Codebase patterns
@services/portfolio_svc/app/routes/aggregation.py
@services/common/db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement export utilities module</name>
  <files>services/common/export.py</files>
  <action>
Create `services/common/export.py` with shared CSV and Excel export functions following research pattern (openpyxl for Excel, csv module for CSV):

```python
from __future__ import annotations
from typing import List, Dict, Any
from io import BytesIO, StringIO
import csv

from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.utils import get_column_letter

def export_to_csv(data: List[Dict[str, Any]], columns: List[str]) -> str:
    """Export data to CSV string using Python csv module.

    Args:
        data: List of dictionaries with row data
        columns: Ordered list of column names to export

    Returns:
        CSV string with proper quoting and escaping (RFC 4180)
    """
    output = StringIO()
    writer = csv.DictWriter(output, fieldnames=columns, extrasaction='ignore')

    writer.writeheader()
    for row in data:
        writer.writerow(row)

    return output.getvalue()


def export_to_excel(
    sheets: Dict[str, Dict[str, Any]],
    title: str = "Regulatory Report",
) -> BytesIO:
    """Export data to Excel workbook with formatting.

    Args:
        sheets: Dict of sheet_name -> {headers: List[str], data: List[Dict], formats: Dict}
        title: Report title

    Returns:
        BytesIO buffer containing Excel workbook

    Example:
        sheets = {
            "Summary": {
                "headers": ["Metric", "Value"],
                "data": [{"Metric": "Total Allowance", "Value": 1000000}],
                "formats": {"Value": "$#,##0.00"},
            },
            "Audit Trail": {
                "headers": ["Audit ID", "Computed At"],
                "data": [{"Audit ID": "abc-123", "Computed At": "2026-02-11"}],
            }
        }
    """
    wb = Workbook()
    wb.remove(wb.active)  # Remove default sheet

    # Styling
    header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
    header_font = Font(bold=True, color="FFFFFF", size=11)
    border = Border(
        left=Side(style='thin'),
        right=Side(style='thin'),
        top=Side(style='thin'),
        bottom=Side(style='thin')
    )

    for sheet_name, sheet_config in sheets.items():
        ws = wb.create_sheet(sheet_name)
        headers = sheet_config["headers"]
        data = sheet_config.get("data", [])
        formats = sheet_config.get("formats", {})

        # Write headers
        for col_idx, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col_idx)
            cell.value = header
            cell.fill = header_fill
            cell.font = header_font
            cell.border = border
            cell.alignment = Alignment(horizontal='center')

        # Write data rows
        for row_idx, row_data in enumerate(data, 2):
            for col_idx, header in enumerate(headers, 1):
                cell = ws.cell(row=row_idx, column=col_idx)
                value = row_data.get(header)
                cell.value = value
                cell.border = border

                # Apply number format if specified
                if header in formats:
                    cell.number_format = formats[header]

        # Auto-adjust column widths
        for col_idx, header in enumerate(headers, 1):
            col_letter = get_column_letter(col_idx)
            max_length = len(str(header))
            for row_idx, row_data in enumerate(data, 2):
                value_length = len(str(row_data.get(header, "")))
                max_length = max(max_length, value_length)
            ws.column_dimensions[col_letter].width = min(max_length + 2, 50)

    # Write to BytesIO
    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)

    return buffer
```

Install openpyxl if not present (add to requirements or install via pip).
  </action>
  <verify>
```bash
# Verify import
python -c "from services.common.export import export_to_csv, export_to_excel; print('Export utils OK')"

# Test CSV export
python -c "
from services.common.export import export_to_csv
data = [{'name': 'Test', 'value': 100}]
csv_output = export_to_csv(data, ['name', 'value'])
assert 'name,value' in csv_output
print('CSV export OK')
"

# Test Excel export
python -c "
from services.common.export import export_to_excel
sheets = {
    'Test': {
        'headers': ['Name', 'Value'],
        'data': [{'Name': 'Test', 'Value': 100}]
    }
}
buffer = export_to_excel(sheets, title='Test Report')
assert buffer.tell() == 0  # Buffer at start
print('Excel export OK')
"
```
  </verify>
  <done>Export utilities module created with CSV (Python csv module) and Excel (openpyxl) functions, tested and working</done>
</task>

<task type="auto">
  <name>Task 2: Implement regulatory reports export routes</name>
  <files>services/regulatory_svc/app/routes/reports.py</files>
  <action>
Complete `services/regulatory_svc/app/routes/reports.py` with export endpoints for CECL, Basel, and audit trail:

```python
from __future__ import annotations
from fastapi import APIRouter, HTTPException, Response, Query
from typing import Dict, Any, List
from datetime import datetime

from services.common.db import db_conn
from services.common.export import export_to_csv, export_to_excel
from psycopg.rows import dict_row

router = APIRouter()

@router.get("/regulatory/{portfolio_id}/export")
def export_regulatory_report(
    portfolio_id: str,
    format: str = Query("xlsx", regex="^(csv|xlsx)$"),
    include_audit_trail: bool = Query(True),
    start_date: str = Query(None),
    end_date: str = Query(None),
) -> Response:
    """Export regulatory report with CECL, Basel, and optional audit trail.

    Args:
        portfolio_id: Portfolio node ID
        format: Export format (csv or xlsx)
        include_audit_trail: Include audit trail sheet/section
        start_date: Filter start date (ISO format)
        end_date: Filter end date (ISO format)

    Returns:
        CSV or Excel file as downloadable response
    """

    # 1. Fetch regulatory metrics for portfolio
    with db_conn() as conn:
        conn.row_factory = dict_row

        # Regulatory metrics summary
        metrics = conn.execute("""
            SELECT
              metric_type,
              metric_value,
              as_of_date,
              metric_breakdown_json
            FROM regulatory_metrics
            WHERE portfolio_node_id = %(pid)s
              AND (%(start)s IS NULL OR as_of_date >= %(start)s::timestamptz)
              AND (%(end)s IS NULL OR as_of_date <= %(end)s::timestamptz)
            ORDER BY as_of_date DESC, metric_type
        """, {
            'pid': portfolio_id,
            'start': start_date,
            'end': end_date,
        }).fetchall()

        if not metrics:
            raise HTTPException(status_code=404, detail="No regulatory metrics found")

        # Prepare summary data
        summary_data = []
        for m in metrics:
            summary_data.append({
                "Metric Type": m['metric_type'],
                "Value": float(m['metric_value']),
                "As Of Date": m['as_of_date'].isoformat() if hasattr(m['as_of_date'], 'isoformat') else str(m['as_of_date']),
            })

        # 2. Fetch audit trail if requested
        audit_data = []
        if include_audit_trail:
            audit_entries = conn.execute("""
                SELECT
                  audit_id,
                  audit_type,
                  calculation_method,
                  computed_at,
                  assumptions_json,
                  results_json
                FROM audit_trail
                WHERE entity_id = %(pid)s
                  AND (%(start)s IS NULL OR computed_at >= %(start)s::timestamptz)
                  AND (%(end)s IS NULL OR computed_at <= %(end)s::timestamptz)
                ORDER BY computed_at DESC
                LIMIT 100
            """, {
                'pid': portfolio_id,
                'start': start_date,
                'end': end_date,
            }).fetchall()

            for entry in audit_entries:
                audit_data.append({
                    "Audit ID": entry['audit_id'],
                    "Type": entry['audit_type'],
                    "Method": entry['calculation_method'],
                    "Computed At": entry['computed_at'].isoformat() if hasattr(entry['computed_at'], 'isoformat') else str(entry['computed_at']),
                    "Assumptions": str(entry['assumptions_json']),
                    "Results": str(entry['results_json']),
                })

    # 3. Generate export
    if format == "csv":
        # For CSV, combine summary and audit into single CSV with section headers
        csv_rows = []
        csv_rows.append({"Section": "Regulatory Metrics Summary"})
        csv_rows.extend([{"Section": "", **row} for row in summary_data])

        if include_audit_trail and audit_data:
            csv_rows.append({"Section": ""})
            csv_rows.append({"Section": "Audit Trail"})
            csv_rows.extend([{"Section": "", **row} for row in audit_data])

        # Determine all columns
        all_columns = ["Section"]
        if summary_data:
            all_columns.extend(summary_data[0].keys())
        if audit_data and include_audit_trail:
            for col in audit_data[0].keys():
                if col not in all_columns:
                    all_columns.append(col)

        csv_content = export_to_csv(csv_rows, all_columns)

        return Response(
            content=csv_content,
            media_type="text/csv",
            headers={
                "Content-Disposition": f'attachment; filename="regulatory-{portfolio_id}-{datetime.utcnow().strftime("%Y%m%d")}.csv"'
            }
        )

    elif format == "xlsx":
        # For Excel, create separate sheets
        sheets = {
            "Summary": {
                "headers": ["Metric Type", "Value", "As Of Date"],
                "data": summary_data,
                "formats": {"Value": "$#,##0.00"},
            }
        }

        if include_audit_trail and audit_data:
            sheets["Audit Trail"] = {
                "headers": ["Audit ID", "Type", "Method", "Computed At", "Assumptions", "Results"],
                "data": audit_data,
            }

        excel_buffer = export_to_excel(sheets, title=f"Regulatory Report - {portfolio_id}")

        return Response(
            content=excel_buffer.getvalue(),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": f'attachment; filename="regulatory-{portfolio_id}-{datetime.utcnow().strftime("%Y%m%d")}.xlsx"'
            }
        )


@router.get("/cecl/{portfolio_id}/export")
def export_cecl_report(
    portfolio_id: str,
    format: str = Query("xlsx", regex="^(csv|xlsx)$"),
) -> Response:
    """Export CECL allowance report by segment."""

    # Fetch latest CECL calculation from regulatory_metrics
    with db_conn() as conn:
        conn.row_factory = dict_row

        cecl_metric = conn.execute("""
            SELECT metric_value, metric_breakdown_json, as_of_date
            FROM regulatory_metrics
            WHERE portfolio_node_id = %(pid)s
              AND metric_type = 'CECL_ALLOWANCE'
            ORDER BY as_of_date DESC
            LIMIT 1
        """, {'pid': portfolio_id}).fetchone()

        if not cecl_metric:
            raise HTTPException(status_code=404, detail="No CECL allowance found")

        total_allowance = float(cecl_metric['metric_value'])
        by_segment = cecl_metric['metric_breakdown_json'].get('by_segment', {})
        as_of_date = cecl_metric['as_of_date']

        # Prepare segment data
        segment_data = []
        for segment_id, allowance in by_segment.items():
            segment_data.append({
                "Segment": segment_id,
                "Allowance": float(allowance),
                "% of Total": (float(allowance) / total_allowance * 100) if total_allowance > 0 else 0.0,
            })

        # Add total row
        segment_data.append({
            "Segment": "TOTAL",
            "Allowance": total_allowance,
            "% of Total": 100.0,
        })

    if format == "csv":
        csv_content = export_to_csv(segment_data, ["Segment", "Allowance", "% of Total"])
        return Response(
            content=csv_content,
            media_type="text/csv",
            headers={
                "Content-Disposition": f'attachment; filename="cecl-{portfolio_id}-{as_of_date}.csv"'
            }
        )
    elif format == "xlsx":
        sheets = {
            "CECL Allowance": {
                "headers": ["Segment", "Allowance", "% of Total"],
                "data": segment_data,
                "formats": {
                    "Allowance": "$#,##0.00",
                    "% of Total": "0.00%",
                },
            }
        }
        excel_buffer = export_to_excel(sheets, title=f"CECL Allowance - {portfolio_id}")

        return Response(
            content=excel_buffer.getvalue(),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": f'attachment; filename="cecl-{portfolio_id}-{as_of_date}.xlsx"'
            }
        )
```

Update imports in `services/regulatory_svc/app/main.py` (already included in Plan 03).
  </action>
  <verify>
```bash
# Verify route import
python -c "from services.regulatory_svc.app.routes.reports import router; print('Reports routes OK')"

# Test export endpoint (requires running service)
# curl -X GET http://localhost:8006/api/v1/regulatory/reports/regulatory/test-portfolio/export?format=csv
```
  </verify>
  <done>Export routes implemented with CSV and Excel generation, integrated with regulatory_metrics and audit_trail tables, ready for frontend download</done>
</task>

<task type="auto">
  <name>Task 3: Commit export pipeline</name>
  <files>
    services/regulatory_svc/app/routes/reports.py
    services/common/export.py
  </files>
  <action>
Commit export pipeline files:

```bash
node C:/Users/omack/.claude/get-shit-done/bin/gsd-tools.js commit \
  "feat(04-04): implement CSV/Excel export pipeline for regulatory reports with openpyxl formatting" \
  --files services/regulatory_svc/app/routes/reports.py services/common/export.py
```
  </action>
  <verify>
```bash
# Verify commit
git log --oneline -1 | grep -q "04-04" && echo "Commit found" || echo "Commit missing"

# Verify files tracked
git ls-files | grep -q "export.py" && echo "Export module tracked" || echo "Missing"
```
  </verify>
  <done>Export pipeline committed with CSV and Excel generation, ready for Phase 4 frontend integration</done>
</task>

</tasks>

<verification>
# Export Utilities
- [ ] export_to_csv produces RFC 4180 compliant CSV
- [ ] export_to_excel uses openpyxl with cell formatting
- [ ] Excel workbooks have multiple sheets with headers
- [ ] Number formats applied (currency, percentage)

# Export Routes
- [ ] GET /reports/regulatory/{portfolio_id}/export returns CSV or Excel
- [ ] GET /reports/cecl/{portfolio_id}/export returns CECL segment breakdown
- [ ] Exports include audit trail when requested
- [ ] Filename includes portfolio ID and timestamp

# Integration
- [ ] Export routes query regulatory_metrics table
- [ ] Audit trail included in exports when requested
- [ ] CSV and Excel formats both working
</verification>

<success_criteria>
1. CSV export uses Python csv module with proper quoting and escaping
2. Excel export uses openpyxl with cell formatting and number formats
3. Regulatory reports include summary and optional audit trail sheets
4. Export endpoints return downloadable files with appropriate Content-Disposition headers
5. CECL and Basel reports export with segment-level breakdown
6. Export format selectable via query parameter (csv or xlsx)
</success_criteria>

<output>
After completion, create `.planning/phases/04-regulatory-analytics-reporting/04-04-SUMMARY.md`
</output>
