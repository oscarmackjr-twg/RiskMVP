---
phase: 04-regulatory-analytics-reporting
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-02"]
files_modified:
  - services/regulatory_svc/app/routes/cecl.py
  - services/regulatory_svc/app/routes/basel.py
  - services/regulatory_svc/app/routes/accounting.py
  - services/regulatory_svc/app/routes/audit.py
  - services/regulatory_svc/app/routes/model_governance.py
  - services/regulatory_svc/app/models.py
  - services/common/audit.py
autonomous: true

must_haves:
  truths:
    - "CECL allowance API returns segment-level breakdown with audit trail"
    - "Basel RWA API computes capital ratios with regulatory reference lookups"
    - "Audit trail API queries are immutable and traceable to calculations"
    - "Model governance API tracks approved/testing/deprecated model versions"
  artifacts:
    - path: "services/regulatory_svc/app/routes/cecl.py"
      provides: "CECL calculation endpoints"
      exports: ["POST /cecl/allowance", "GET /cecl/staging"]
      min_lines: 150
    - path: "services/regulatory_svc/app/routes/basel.py"
      provides: "Basel III calculation endpoints"
      exports: ["POST /basel/rwa", "GET /basel/capital-ratios"]
      min_lines: 120
    - path: "services/regulatory_svc/app/routes/audit.py"
      provides: "Audit trail query endpoints"
      exports: ["GET /audit/{audit_id}", "GET /audit/search", "GET /audit/explainability"]
      min_lines: 100
    - path: "services/common/audit.py"
      provides: "Shared audit trail logging function"
      exports: ["log_audit_entry"]
      min_lines: 50
  key_links:
    - from: "POST /cecl/allowance"
      to: "compute.regulatory.cecl.compute_cecl_allowance"
      via: "function call with portfolio data"
      pattern: "from compute\\.regulatory\\.cecl import compute_cecl_allowance"
    - from: "log_audit_entry"
      to: "audit_trail table"
      via: "INSERT with immutable guarantee"
      pattern: "INSERT INTO audit_trail"
    - from: "GET /basel/rwa"
      to: "regulatory_reference table"
      via: "risk weight lookup query"
      pattern: "SELECT.*regulatory_reference.*RISK_WEIGHT"
---

<objective>
Implement Regulatory Service REST API with CECL, Basel III, GAAP/IFRS, audit trail, and model governance endpoints. Integrate with Plan 02 compute modules and Plan 01 database schema.

Purpose: Deliver REG-01 through REG-05 API layer. Enable Phase 4 frontend to query regulatory calculations with full audit compliance.

Output: Regulatory service running on port 8006 with 15+ endpoints, integrated with compute layer and audit trail.
</objective>

<execution_context>
@C:/Users/omack/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/omack/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-regulatory-analytics-reporting/04-RESEARCH.md
@.planning/phases/04-regulatory-analytics-reporting/04-01-PLAN.md
@.planning/phases/04-regulatory-analytics-reporting/04-02-PLAN.md

# Existing service patterns
@services/portfolio_svc/app/main.py
@services/portfolio_svc/app/routes/aggregation.py
@services/common/db.py

# Compute modules from Plan 02
@compute/regulatory/cecl.py
@compute/regulatory/basel.py
@compute/regulatory/gaap_ifrs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement CECL and Basel III route handlers with regulatory_metrics persistence (REG-02, REG-03)</name>
  <files>
    services/regulatory_svc/app/routes/cecl.py
    services/regulatory_svc/app/routes/basel.py
    services/regulatory_svc/app/models.py
    services/common/audit.py
  </files>
  <action>
**services/regulatory_svc/app/routes/cecl.py** - CECL calculation endpoints:

```python
from __future__ import annotations
from typing import Dict, Any, List
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from datetime import datetime
from uuid import uuid4

from compute.regulatory.cecl import compute_cecl_allowance, stage_classification
from services.common.db import db_conn
from services.common.audit import log_audit_entry
from psycopg.rows import dict_row
from psycopg.types.json import Json

router = APIRouter()

class CECLRequest(BaseModel):
    portfolio_node_id: str
    as_of_date: str  # ISO date
    scenario_set_id: str = "BASE_SCENARIOS"
    q_factor: float = Field(default=0.0, ge=0.0, le=0.5)

class CECLResponse(BaseModel):
    total_allowance: float
    by_segment: Dict[str, float]
    scenario_detail: List[Dict[str, Any]]
    audit_id: str

@router.post("/allowance", response_model=CECLResponse)
def calculate_cecl_allowance(req: CECLRequest) -> CECLResponse:
    """Compute CECL allowance using ASC 326 multi-scenario approach."""

    # 1. Fetch portfolio positions with EAD, rating, issuer
    with db_conn() as conn:
        conn.row_factory = dict_row
        positions = conn.execute("""
            SELECT
              pos.position_id,
              pos.instrument_id,
              (vr.measures_json ->> 'PV')::numeric AS ead,
              ref.entity_id AS issuer_id,
              COALESCE(rh.rating, 'BBB') AS rating,
              pos.base_ccy
            FROM position pos
            LEFT JOIN instrument instr ON pos.instrument_id = instr.instrument_id
            LEFT JOIN reference_data ref ON instr.payload_json ->> 'issuer_id' = ref.entity_id
            LEFT JOIN rating_history rh ON ref.entity_id = rh.entity_id
              AND rh.as_of_date <= %(as_of)s::timestamptz
              ORDER BY rh.as_of_date DESC LIMIT 1
            LEFT JOIN valuation_result vr ON pos.position_id = vr.position_id
              AND vr.scenario_id = 'BASE'
            WHERE pos.portfolio_node_id = %(pid)s
              AND instr.product_type IN ('AMORT_LOAN', 'CREDIT_CARD', 'MORTGAGE')
        """, {'pid': req.portfolio_node_id, 'as_of': req.as_of_date}).fetchall()

        if not positions:
            raise HTTPException(status_code=404, detail="No loan positions found")

        # 2. Fetch PD curves from regulatory_reference
        pd_curves = {}
        pd_data = conn.execute("""
            SELECT entity_key AS rating, ref_value AS pd_annual
            FROM regulatory_reference
            WHERE ref_type = 'PD_CURVE'
              AND effective_date <= %(as_of)s::timestamptz
              AND (expired_date IS NULL OR expired_date > %(as_of)s::timestamptz)
            ORDER BY entity_key, effective_date DESC
        """, {'as_of': req.as_of_date}).fetchall()

        for row in pd_data:
            rating = row['rating']
            if rating not in pd_curves:
                pd_curves[rating] = []
            pd_curves[rating].append(float(row['pd_annual']))

        # Default PD curve if none found
        if not pd_curves:
            pd_curves = {
                "AAA": [0.005, 0.007, 0.009, 0.011, 0.013],
                "BBB": [0.010, 0.015, 0.020, 0.025, 0.030],
                "BB": [0.030, 0.045, 0.060, 0.075, 0.090],
            }

        # 3. Fetch LGD assumptions
        lgd_assumptions = {"default": 0.45}  # Simplified for MVP

        # 4. Define macro scenarios (MVP: single base scenario)
        macro_scenarios = [{"base_rate": 2.5, "unemployment": 4.2}]
        scenario_weights = [1.0]

        # 5. Compute CECL allowance
        result = compute_cecl_allowance(
            portfolio=[dict(p) for p in positions],
            pd_curves=pd_curves,
            lgd_assumptions=lgd_assumptions,
            macro_scenarios=macro_scenarios,
            scenario_weights=scenario_weights,
        )

        # Apply Q-factor
        result["total_allowance"] *= (1 + req.q_factor)
        for seg in result["by_segment"]:
            result["by_segment"][seg] *= (1 + req.q_factor)

        # 6. Log to audit trail
        audit_id = log_audit_entry(
            audit_type="CECL",
            calculation_run_id=f"cecl-{req.portfolio_node_id}-{req.as_of_date}",
            entity_type="PORTFOLIO",
            entity_id=req.portfolio_node_id,
            calculation_method="ASC326_MULTI_SCENARIO",
            input_snapshot_id="N/A",  # No market snapshot for CECL
            assumptions={
                "scenario_set_id": req.scenario_set_id,
                "q_factor": req.q_factor,
                "lgd_default": lgd_assumptions["default"],
            },
            results={
                "total_allowance": result["total_allowance"],
                "by_segment": result["by_segment"],
            },
        )

        # 7. UPSERT to regulatory_metrics table
        conn.execute("""
            INSERT INTO regulatory_metrics
              (portfolio_node_id, metric_type, metric_value, as_of_date, metric_breakdown_json, metadata_json)
            VALUES (%(pid)s, 'CECL_ALLOWANCE', %(val)s, %(as_of)s::timestamptz, %(breakdown)s, %(meta)s)
            ON CONFLICT (portfolio_node_id, metric_type, as_of_date)
            DO UPDATE SET
              metric_value = EXCLUDED.metric_value,
              metric_breakdown_json = EXCLUDED.metric_breakdown_json,
              metadata_json = EXCLUDED.metadata_json,
              computed_at = now()
        """, {
            'pid': req.portfolio_node_id,
            'val': result["total_allowance"],
            'as_of': req.as_of_date,
            'breakdown': Json({
                'by_segment': result["by_segment"],
                'scenario_detail': result.get("scenario_detail", []),
            }),
            'meta': Json({
                'q_factor': req.q_factor,
                'scenario_set_id': req.scenario_set_id,
                'audit_id': audit_id,
            })
        })
        conn.commit()

        return CECLResponse(
            total_allowance=result["total_allowance"],
            by_segment=result["by_segment"],
            scenario_detail=result.get("scenario_detail", []),
            audit_id=audit_id,
        )

@router.get("/staging/{portfolio_id}")
def get_cecl_staging(portfolio_id: str):
    """Get CECL stage classification for portfolio positions.

    Returns stage distribution: {stage_1: count, stage_2: count, stage_3: count}
    """

    with db_conn() as conn:
        conn.row_factory = dict_row

        # Fetch positions with PD data for staging
        positions = conn.execute("""
            SELECT
              pos.position_id,
              COALESCE(rh_current.pd_value, 0.02) AS current_pd,
              COALESCE(rh_orig.pd_value, 0.01) AS origination_pd,
              COALESCE(
                EXTRACT(DAY FROM (now() - pos.metadata_json->>'last_payment_date'::text)::interval),
                0
              )::int AS days_past_due
            FROM position pos
            LEFT JOIN instrument instr ON pos.instrument_id = instr.instrument_id
            LEFT JOIN reference_data ref ON instr.payload_json ->> 'issuer_id' = ref.entity_id
            LEFT JOIN rating_history rh_current ON ref.entity_id = rh_current.entity_id
              AND rh_current.as_of_date <= now()
              ORDER BY rh_current.as_of_date DESC LIMIT 1
            LEFT JOIN rating_history rh_orig ON ref.entity_id = rh_orig.entity_id
              AND rh_orig.as_of_date <= (pos.metadata_json->>'origination_date')::timestamptz
              ORDER BY rh_orig.as_of_date DESC LIMIT 1
            WHERE pos.portfolio_node_id = %(pid)s
              AND instr.product_type IN ('AMORT_LOAN', 'CREDIT_CARD', 'MORTGAGE')
        """, {'pid': portfolio_id}).fetchall()

        if not positions:
            raise HTTPException(status_code=404, detail="No loan positions found")

        # Classify stages
        stage_counts = {1: 0, 2: 0, 3: 0}
        position_stages = []

        for pos in positions:
            stage = stage_classification(
                current_pd=float(pos['current_pd']),
                origination_pd=float(pos['origination_pd']),
                days_past_due=pos['days_past_due']
            )
            stage_counts[stage] += 1
            position_stages.append({
                'position_id': pos['position_id'],
                'stage': stage,
                'current_pd': float(pos['current_pd']),
                'origination_pd': float(pos['origination_pd']),
                'days_past_due': pos['days_past_due'],
            })

        return {
            'portfolio_id': portfolio_id,
            'stage_distribution': stage_counts,
            'total_positions': len(positions),
            'positions': position_stages,
        }
```

**services/regulatory_svc/app/routes/basel.py** - Basel III RWA endpoints:

```python
from __future__ import annotations
from typing import Dict, Any
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from compute.regulatory.basel import compute_basel_rwa, compute_capital_ratios
from services.common.db import db_conn
from services.common.audit import log_audit_entry
from psycopg.rows import dict_row
from psycopg.types.json import Json

router = APIRouter()

class BaselRWARequest(BaseModel):
    portfolio_node_id: str
    as_of_date: str
    tier1_capital: float
    tier2_capital: float

class BaselRWAResponse(BaseModel):
    total_rwa: float
    by_counterparty_type: Dict[str, float]
    by_rating: Dict[str, float]
    capital_ratios: Dict[str, float]
    audit_id: str

@router.post("/rwa", response_model=BaselRWAResponse)
def calculate_basel_rwa(req: BaselRWARequest) -> BaselRWAResponse:
    """Compute Basel III RWA using standardized approach."""

    # 1. Fetch portfolio positions with EAD, counterparty type, rating
    with db_conn() as conn:
        conn.row_factory = dict_row
        positions = conn.execute("""
            SELECT
              pos.position_id,
              (vr.measures_json ->> 'PV')::numeric AS ead,
              COALESCE(ref.entity_type, 'UNRATED') AS counterparty_type,
              COALESCE(rh.rating, 'UNRATED') AS rating
            FROM position pos
            LEFT JOIN instrument instr ON pos.instrument_id = instr.instrument_id
            LEFT JOIN reference_data ref ON instr.payload_json ->> 'issuer_id' = ref.entity_id
            LEFT JOIN rating_history rh ON ref.entity_id = rh.entity_id
              AND rh.as_of_date <= %(as_of)s::timestamptz
              ORDER BY rh.as_of_date DESC LIMIT 1
            LEFT JOIN valuation_result vr ON pos.position_id = vr.position_id
              AND vr.scenario_id = 'BASE'
            WHERE pos.portfolio_node_id = %(pid)s
        """, {'pid': req.portfolio_node_id, 'as_of': req.as_of_date}).fetchall()

        if not positions:
            raise HTTPException(status_code=404, detail="No positions found")

        # 2. Fetch risk weights from regulatory_reference
        risk_weight_data = conn.execute("""
            SELECT entity_key, ref_value
            FROM regulatory_reference
            WHERE ref_type = 'RISK_WEIGHT'
              AND effective_date <= %(as_of)s::timestamptz
              AND (expired_date IS NULL OR expired_date > %(as_of)s::timestamptz)
        """, {'as_of': req.as_of_date}).fetchall()

        risk_weights = {}
        for row in risk_weight_data:
            # entity_key format: "CORPORATE/AAA" or "RETAIL/ANY"
            parts = row['entity_key'].split('/')
            if len(parts) == 2:
                risk_weights[(parts[0], parts[1])] = float(row['ref_value'])

        # Default risk weights if not in DB
        if not risk_weights:
            risk_weights = {
                ('SOVEREIGN', 'AAA'): 0.00,
                ('SOVEREIGN', 'AA'): 0.20,
                ('CORPORATE', 'AAA'): 0.20,
                ('CORPORATE', 'BBB'): 1.00,
                ('CORPORATE', 'BB'): 1.50,
                ('RETAIL', 'ANY'): 0.75,
                ('UNRATED', 'ANY'): 1.00,
            }

        # 3. Compute RWA
        rwa_result = compute_basel_rwa(
            portfolio=[dict(p) for p in positions],
            risk_weights=risk_weights,
        )

        # 4. Compute capital ratios
        capital_ratios = compute_capital_ratios(
            total_rwa=rwa_result["total_rwa"],
            tier1_capital=req.tier1_capital,
            tier2_capital=req.tier2_capital,
        )

        # 5. Log to audit trail
        audit_id = log_audit_entry(
            audit_type="BASEL",
            calculation_run_id=f"basel-{req.portfolio_node_id}-{req.as_of_date}",
            entity_type="PORTFOLIO",
            entity_id=req.portfolio_node_id,
            calculation_method="BASEL3_STANDARDIZED",
            input_snapshot_id="N/A",
            assumptions={
                "tier1_capital": req.tier1_capital,
                "tier2_capital": req.tier2_capital,
            },
            results={
                "total_rwa": rwa_result["total_rwa"],
                "capital_ratios": capital_ratios,
            },
        )

        # 6. UPSERT to regulatory_metrics table
        conn.execute("""
            INSERT INTO regulatory_metrics
              (portfolio_node_id, metric_type, metric_value, as_of_date, metric_breakdown_json, metadata_json)
            VALUES (%(pid)s, 'BASEL_RWA', %(val)s, %(as_of)s::timestamptz, %(breakdown)s, %(meta)s)
            ON CONFLICT (portfolio_node_id, metric_type, as_of_date)
            DO UPDATE SET
              metric_value = EXCLUDED.metric_value,
              metric_breakdown_json = EXCLUDED.metric_breakdown_json,
              metadata_json = EXCLUDED.metadata_json,
              computed_at = now()
        """, {
            'pid': req.portfolio_node_id,
            'val': rwa_result["total_rwa"],
            'as_of': req.as_of_date,
            'breakdown': Json({
                'by_counterparty_type': rwa_result["by_counterparty_type"],
                'by_rating': rwa_result["by_rating"],
                'capital_ratios': capital_ratios,
            }),
            'meta': Json({
                'tier1_capital': req.tier1_capital,
                'tier2_capital': req.tier2_capital,
                'audit_id': audit_id,
            })
        })
        conn.commit()

        return BaselRWAResponse(
            total_rwa=rwa_result["total_rwa"],
            by_counterparty_type=rwa_result["by_counterparty_type"],
            by_rating=rwa_result["by_rating"],
            capital_ratios=capital_ratios,
            audit_id=audit_id,
        )
```

**services/common/audit.py** - Shared audit trail logging:

```python
from __future__ import annotations
from typing import Dict, Any
from uuid import uuid4
from datetime import datetime

from services.common.db import db_conn
from psycopg.types.json import Json

def log_audit_entry(
    audit_type: str,
    calculation_run_id: str,
    entity_type: str,
    entity_id: str,
    calculation_method: str,
    input_snapshot_id: str,
    assumptions: Dict[str, Any],
    results: Dict[str, Any],
) -> str:
    """Log immutable audit entry. Returns audit_id."""

    audit_id = str(uuid4())

    with db_conn() as conn:
        conn.execute("""
            INSERT INTO audit_trail
              (audit_id, audit_type, calculation_run_id, entity_type, entity_id,
               calculation_method, input_snapshot_id, input_version, assumptions_json,
               results_json, metadata_json, computed_at)
            VALUES (%(aid)s, %(at)s, %(crid)s, %(et)s, %(eid)s,
                    %(cm)s, %(snap)s, %(ver)s, %(assum)s,
                    %(res)s, %(meta)s, now())
        """, {
            'aid': audit_id,
            'at': audit_type,
            'crid': calculation_run_id,
            'et': entity_type,
            'eid': entity_id,
            'cm': calculation_method,
            'snap': input_snapshot_id,
            'ver': 'v1.0.0',  # Model version
            'assum': Json(assumptions),
            'res': Json(results),
            'meta': Json({
                'computed_by': 'regulatory_svc',
                'timestamp': datetime.utcnow().isoformat(),
            })
        })
        conn.commit()

    return audit_id
```

Update `services/regulatory_svc/app/models.py` with request/response models (already defined above as BaseModel classes).
  </action>
  <verify>
```bash
# Verify route imports work
python -c "from services.regulatory_svc.app.routes.cecl import router as cecl_router; print('CECL routes OK')"
python -c "from services.regulatory_svc.app.routes.basel import router as basel_router; print('Basel routes OK')"
python -c "from services.common.audit import log_audit_entry; print('Audit logging OK')"
```
  </verify>
  <done>CECL and Basel routes implemented with audit trail logging AND regulatory_metrics UPSERT, integrated with compute modules from Plan 02, ready for service startup</done>
</task>

<task type="auto">
  <name>Task 2: Implement accounting, audit trail, and model governance routes (REG-01, REG-04, REG-05)</name>
  <files>
    services/regulatory_svc/app/routes/accounting.py
    services/regulatory_svc/app/routes/audit.py
    services/regulatory_svc/app/routes/model_governance.py
  </files>
  <action>
**services/regulatory_svc/app/routes/accounting.py** - GAAP/IFRS valuation endpoints:

```python
from __future__ import annotations
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Dict

from compute.regulatory.gaap_ifrs import (
    classify_gaap_category,
    classify_ifrs_category,
    compute_gaap_valuation,
    compute_ifrs_valuation,
)
from services.common.db import db_conn
from psycopg.rows import dict_row

router = APIRouter()

class AccountingValuationRequest(BaseModel):
    position_id: str
    framework: str  # "GAAP" or "IFRS"
    ecl_allowance: float = 0.0

class AccountingValuationResponse(BaseModel):
    position_id: str
    framework: str
    category: str
    carrying_value: float
    market_value: float
    book_value: float
    unrealized_gain_loss: float = 0.0
    impairment: float = 0.0
    ecl_allowance: float = 0.0

@router.post("/valuation", response_model=AccountingValuationResponse)
def calculate_accounting_valuation(req: AccountingValuationRequest) -> AccountingValuationResponse:
    """Compute GAAP or IFRS valuation for a position."""

    # Fetch position with market value, book value, metadata
    with db_conn() as conn:
        conn.row_factory = dict_row
        position = conn.execute("""
            SELECT
              pos.position_id,
              pos.cost_basis AS book_value,
              (vr.measures_json ->> 'PV')::numeric AS market_value,
              pos.metadata_json
            FROM position pos
            LEFT JOIN valuation_result vr ON pos.position_id = vr.position_id
              AND vr.scenario_id = 'BASE'
            WHERE pos.position_id = %(pid)s
        """, {'pid': req.position_id}).fetchone()

        if not position:
            raise HTTPException(status_code=404, detail="Position not found")

        market_value = float(position['market_value'] or 0)
        book_value = float(position['book_value'] or 0)
        metadata = position['metadata_json'] or {}

        # Compute valuation
        if req.framework == "GAAP":
            result = compute_gaap_valuation(
                position=metadata,
                market_value=market_value,
                book_value=book_value,
            )
        elif req.framework == "IFRS":
            result = compute_ifrs_valuation(
                position=metadata,
                market_value=market_value,
                book_value=book_value,
                ecl_allowance=req.ecl_allowance,
            )
        else:
            raise HTTPException(status_code=400, detail="Framework must be GAAP or IFRS")

        return AccountingValuationResponse(
            position_id=req.position_id,
            framework=req.framework,
            category=result["category"],
            carrying_value=result["carrying_value"],
            market_value=market_value,
            book_value=book_value,
            unrealized_gain_loss=result.get("unrealized_gain_loss", 0.0),
            impairment=result.get("impairment", 0.0),
            ecl_allowance=result.get("ecl_allowance", 0.0),
        )
```

**services/regulatory_svc/app/routes/audit.py** - Audit trail queries:

```python
from __future__ import annotations
from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel
from typing import List, Dict, Any

from services.common.db import db_conn
from psycopg.rows import dict_row

router = APIRouter()

class AuditEntry(BaseModel):
    audit_id: str
    audit_type: str
    calculation_method: str
    entity_id: str
    computed_at: str
    assumptions_json: Dict[str, Any]
    results_json: Dict[str, Any]

@router.get("/{audit_id}", response_model=AuditEntry)
def get_audit_entry(audit_id: str) -> AuditEntry:
    """Retrieve audit entry by ID."""
    with db_conn() as conn:
        conn.row_factory = dict_row
        entry = conn.execute("""
            SELECT audit_id, audit_type, calculation_method, entity_id,
                   computed_at, assumptions_json, results_json
            FROM audit_trail
            WHERE audit_id = %(aid)s
        """, {'aid': audit_id}).fetchone()

        if not entry:
            raise HTTPException(status_code=404, detail="Audit entry not found")

        return AuditEntry(**dict(entry))

@router.get("/search", response_model=List[AuditEntry])
def search_audit_trail(
    entity_id: str = Query(None),
    audit_type: str = Query(None),
    start_date: str = Query(None),
    end_date: str = Query(None),
    limit: int = Query(50, le=200),
) -> List[AuditEntry]:
    """Search audit trail with filters."""
    filters = []
    params = {}

    if entity_id:
        filters.append("entity_id = %(entity_id)s")
        params['entity_id'] = entity_id
    if audit_type:
        filters.append("audit_type = %(audit_type)s")
        params['audit_type'] = audit_type
    if start_date:
        filters.append("computed_at >= %(start_date)s::timestamptz")
        params['start_date'] = start_date
    if end_date:
        filters.append("computed_at <= %(end_date)s::timestamptz")
        params['end_date'] = end_date

    where_clause = " AND ".join(filters) if filters else "TRUE"

    with db_conn() as conn:
        conn.row_factory = dict_row
        entries = conn.execute(f"""
            SELECT audit_id, audit_type, calculation_method, entity_id,
                   computed_at, assumptions_json, results_json
            FROM audit_trail
            WHERE {where_clause}
            ORDER BY computed_at DESC
            LIMIT %(limit)s
        """, {**params, 'limit': limit}).fetchall()

        return [AuditEntry(**dict(e)) for e in entries]
```

**services/regulatory_svc/app/routes/model_governance.py** - Model versioning:

```python
from __future__ import annotations
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional

from services.common.db import db_conn
from psycopg.rows import dict_row
from psycopg.types.json import Json

router = APIRouter()

class ModelVersion(BaseModel):
    model_version: str
    model_type: str
    git_hash: Optional[str]
    deployment_date: str
    approval_status: str
    backtesting_results_json: Optional[Dict[str, Any]]
    notes: Optional[str]

@router.get("/models", response_model=List[ModelVersion])
def list_models(model_type: str = None) -> List[ModelVersion]:
    """List all model versions."""
    with db_conn() as conn:
        conn.row_factory = dict_row
        if model_type:
            models = conn.execute("""
                SELECT * FROM model_governance
                WHERE model_type = %(mt)s
                ORDER BY deployment_date DESC
            """, {'mt': model_type}).fetchall()
        else:
            models = conn.execute("""
                SELECT * FROM model_governance
                ORDER BY deployment_date DESC
            """).fetchall()

        return [ModelVersion(**dict(m)) for m in models]

@router.post("/models", response_model=ModelVersion)
def register_model(model: ModelVersion) -> ModelVersion:
    """Register new model version."""
    with db_conn() as conn:
        conn.execute("""
            INSERT INTO model_governance
              (model_version, model_type, git_hash, deployment_date, approval_status,
               backtesting_results_json, notes)
            VALUES (%(ver)s, %(type)s, %(hash)s, %(deploy)s, %(status)s, %(back)s, %(notes)s)
        """, {
            'ver': model.model_version,
            'type': model.model_type,
            'hash': model.git_hash,
            'deploy': model.deployment_date,
            'status': model.approval_status,
            'back': Json(model.backtesting_results_json or {}),
            'notes': model.notes,
        })
        conn.commit()

    return model
```
  </action>
  <verify>
```bash
# Verify route imports
python -c "from services.regulatory_svc.app.routes.accounting import router; print('Accounting routes OK')"
python -c "from services.regulatory_svc.app.routes.audit import router; print('Audit routes OK')"
python -c "from services.regulatory_svc.app.routes.model_governance import router; print('Model governance routes OK')"
```
  </verify>
  <done>Accounting, audit trail, and model governance routes implemented with database integration, ready for service startup on port 8006</done>
</task>

<task type="auto">
  <name>Task 3: Update regulatory service main.py and commit</name>
  <files>
    services/regulatory_svc/app/main.py
    services/regulatory_svc/app/routes/model_governance.py
  </files>
  <action>
Update `services/regulatory_svc/app/main.py` to include model_governance router:

```python
"""Regulatory service -- CECL, Basel III, GAAP/IFRS, capital analytics, audit, and reports."""
from __future__ import annotations

from services.common.service_base import create_service_app

from services.regulatory_svc.app.routes.cecl import router as cecl_router
from services.regulatory_svc.app.routes.basel import router as basel_router
from services.regulatory_svc.app.routes.accounting import router as accounting_router
from services.regulatory_svc.app.routes.audit import router as audit_router
from services.regulatory_svc.app.routes.model_governance import router as model_governance_router
from services.regulatory_svc.app.routes.reports import router as reports_router

app = create_service_app(
    title="regulatory-svc",
    description="CECL, Basel III, GAAP/IFRS, capital analytics, audit trail, and regulatory reports",
)

app.include_router(cecl_router, prefix="/api/v1/regulatory/cecl", tags=["CECL"])
app.include_router(basel_router, prefix="/api/v1/regulatory/basel", tags=["Basel III"])
app.include_router(accounting_router, prefix="/api/v1/regulatory/accounting", tags=["Accounting"])
app.include_router(audit_router, prefix="/api/v1/regulatory/audit", tags=["Audit"])
app.include_router(model_governance_router, prefix="/api/v1/regulatory/models", tags=["Model Governance"])
app.include_router(reports_router, prefix="/api/v1/regulatory/reports", tags=["Reports"])
```

Commit all regulatory service files:

```bash
node C:/Users/omack/.claude/get-shit-done/bin/gsd-tools.js commit \
  "feat(04-03): implement regulatory service with CECL, Basel, accounting, audit, and model governance routes" \
  --files services/regulatory_svc/app/routes/*.py services/regulatory_svc/app/models.py services/regulatory_svc/app/main.py services/common/audit.py
```
  </action>
  <verify>
```bash
# Verify service startup
uvicorn services.regulatory_svc.app.main:app --port 8006 &
sleep 3
curl http://localhost:8006/health | grep -q "healthy" && echo "Service OK" || echo "Service failed"
pkill -f "uvicorn.*8006"
```
  </verify>
  <done>Regulatory service updated with all routes, committed to git, service starts successfully on port 8006</done>
</task>

</tasks>

<verification>
# CECL Routes
- [ ] POST /cecl/allowance returns total_allowance with audit_id
- [ ] CECL endpoint fetches PD curves from regulatory_reference
- [ ] Audit trail logged for every CECL calculation
- [ ] regulatory_metrics table populated with CECL results

# Basel Routes
- [ ] POST /basel/rwa returns total_rwa and capital_ratios with audit_id
- [ ] Basel endpoint fetches risk weights from regulatory_reference
- [ ] Audit trail logged for every Basel calculation
- [ ] regulatory_metrics table populated with Basel RWA results

# CECL Staging
- [ ] GET /cecl/staging/{portfolio_id} returns stage distribution
- [ ] Stage classification uses compute module logic
- [ ] No longer raises 501

# Accounting Routes
- [ ] POST /accounting/valuation returns category and carrying_value
- [ ] GAAP and IFRS frameworks produce different results for same position

# Audit Trail Routes
- [ ] GET /audit/{audit_id} returns audit entry
- [ ] GET /audit/search filters by entity_id, audit_type, date range
- [ ] Audit entries are immutable (no UPDATE allowed)

# Model Governance Routes
- [ ] GET /models lists model versions
- [ ] POST /models registers new model version
- [ ] Model versions tracked with git_hash and approval_status

# Service Integration
- [ ] Regulatory service starts on port 8006
- [ ] Health check returns healthy status
- [ ] All routes integrated with compute modules from Plan 02
</verification>

<success_criteria>
1. CECL allowance API integrated with compute module and audit trail
2. Basel RWA API queries regulatory_reference for risk weights
3. GAAP/IFRS accounting framework produces different valuations
4. Audit trail API provides immutable query access
5. Model governance tracks version deployments with backtesting
6. Regulatory service runs on port 8006 with all endpoints functional
7. regulatory_metrics table populated by CECL and Basel endpoints
8. CECL staging endpoint implemented (not stub)
</success_criteria>

<output>
After completion, create `.planning/phases/04-regulatory-analytics-reporting/04-03-SUMMARY.md`
</output>
